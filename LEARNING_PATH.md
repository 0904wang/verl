# verl å­¦ä¹ è·¯çº¿å›¾

`verl` (Volcano Engine Reinforcement Learning) æ˜¯ä¸€ä¸ªä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹ (LLM) è®¾è®¡çš„é«˜æ€§èƒ½å¼ºåŒ–å­¦ä¹  (RL) è®­ç»ƒåº“ã€‚å®ƒåŸºäº Ray å’Œ PyTorch æ„å»ºï¼Œæ”¯æŒ HybridFlow ç¼–ç¨‹æ¨¡å‹ï¼Œèƒ½å¤Ÿçµæ´»é«˜æ•ˆåœ°è¿›è¡Œ PPOã€GRPO ç­‰ç®—æ³•çš„è®­ç»ƒã€‚

ä»¥ä¸‹æ˜¯ä¸ºæ‚¨å®šåˆ¶çš„é€æ–‡ä»¶å­¦ä¹ è·¯çº¿ï¼Œåˆ†ä¸º **å…¥é—¨å‡†å¤‡**ã€**æ ¸å¿ƒæµç¨‹**ã€**å…³é”®ç»„ä»¶**ã€**è¿›é˜¶æ¶æ„** å››ä¸ªé˜¶æ®µã€‚

---

## ğŸ“… ç¬¬ä¸€é˜¶æ®µï¼šå…¥é—¨ä¸å¿«é€Ÿä¸Šæ‰‹ (Quick Start)
**ç›®æ ‡**ï¼šè·‘é€šä¸€ä¸ª Demoï¼Œå»ºç«‹æ„Ÿæ€§è®¤è¯†ã€‚

1.  **å…¨å±€æ¦‚è§ˆ**
    *   **é˜…è¯»æ–‡ä»¶**: `README.md`
    *   **é‡ç‚¹**: äº†è§£ Project æ˜¯åšä»€ä¹ˆçš„ (RL specifically for LLMs)ï¼Œæ ¸å¿ƒç‰¹æ€§ (Modular APIs, HybridFlow, SOTA throughout)ï¼Œä»¥åŠæ”¯æŒçš„ç®—æ³• (PPO, GRPO)ã€‚

2.  **è¿è¡Œç¤ºä¾‹ (Hello World)**
    *   **é˜…è¯»æ–‡ä»¶**: `examples/ppo_trainer/README.md`
    *   **æŸ¥çœ‹è„šæœ¬**: `examples/ppo_trainer/run_deepseek7b_llm.sh` (æˆ–å…¶ä»–ç±»ä¼¼è„šæœ¬)
    *   **è¡ŒåŠ¨**: æŒ‰ç…§ `docs` ä¸­çš„å®‰è£…è¯´æ˜é…ç½®ç¯å¢ƒï¼Œå¹¶å°è¯•è¿è¡Œè¿™ä¸ªè„šæœ¬ã€‚
    *   **æ€è€ƒ**: è„šæœ¬ä¸­ä¼ å…¥äº†å“ªäº›å‚æ•°ï¼Ÿ(æ¯”å¦‚ `actor_rollout_ref.model.path`, `data.train_files`)ï¼Œè¿™ä¸€æ­¥è®©ä½ çŸ¥é“å¦‚ä½•é…ç½®è®­ç»ƒä»»åŠ¡ã€‚

---

## âš™ï¸ ç¬¬äºŒé˜¶æ®µï¼šæ ¸å¿ƒè®­ç»ƒæµç¨‹ (Core Flow)
**ç›®æ ‡**ï¼šç†è§£ä»£ç æ˜¯å¦‚ä½•è¿è¡Œèµ·æ¥çš„ï¼Œæ•°æ®å¦‚ä½•åœ¨ç³»ç»Ÿä¸­æµè½¬ã€‚

3.  **å…¥å£åˆ†æ**
    *   **é˜…è¯»æ–‡ä»¶**: `verl/trainer/main_ppo.py`
    *   **é‡ç‚¹**:
        *   `main` å‡½æ•°ï¼šä½¿ç”¨ `hydra` ç®¡ç†é…ç½®ã€‚
        *   `run_ppo` å‡½æ•°ï¼šåˆå§‹åŒ– Ray é›†ç¾¤ã€‚
        *   `TaskRunner` ç±»ï¼šè¿™æ˜¯æ ¸å¿ƒæŒ‡æŒ¥å®˜ï¼Œè´Ÿè´£ç»„è£… Actor, Critic, RewardModel ç­‰ Workerã€‚
    *   **æ”¶è·**: ç†è§£ç³»ç»Ÿæ˜¯å¦‚ä½•å¯åŠ¨çš„ï¼Œä»¥åŠå„ä¸ªè§’è‰²çš„åˆ›å»ºè¿‡ç¨‹ã€‚

4.  **è®­ç»ƒä¸»å¾ªç¯**
    *   **é˜…è¯»æ–‡ä»¶**: `verl/trainer/ppo/ray_trainer.py`
    *   **é‡ç‚¹å…³æ³¨ç±»**: `RayPPOTrainer`
    *   **é‡ç‚¹æ–¹æ³•**:
        *   `fit()`: è®­ç»ƒçš„ä¸»å¾ªç¯ (Loop)ã€‚
        *   `_create_dataloader`: æ•°æ®åŠ è½½ã€‚
        *   `run_generation`: ç”Ÿæˆ Rollout é˜¶æ®µã€‚
        *   `update_policy`: PPO æ›´æ–°é˜¶æ®µã€‚
    *   **æ”¶è·**: ç†è§£ RLHF çš„è®­ç»ƒå¿ƒè·³ï¼š**Generate (Rollout) -> Compute Reward -> Compute Advantage (GAE/GRPO) -> Update Actor/Critic**ã€‚

---

## ğŸ› ï¸ ç¬¬ä¸‰é˜¶æ®µï¼šå…³é”®å®šåˆ¶ç»„ä»¶ (Customization)
**ç›®æ ‡**ï¼šå­¦ä¼šå¦‚ä½•æ›¿æ¢æ•°æ®ã€ä¿®æ”¹ Reward å‡½æ•°ï¼Œè¿™æ˜¯å®é™…ä½¿ç”¨ä¸­æœ€å¸¸ä¿®æ”¹çš„éƒ¨åˆ†ã€‚

5.  **æ•°æ®å¤„ç†**
    *   **é˜…è¯»æ–‡ä»¶**: `verl/utils/dataset/rl_dataset.py`
    *   **é‡ç‚¹**: `RLDataset` ç±»ï¼Œäº†è§£æ•°æ®æ˜¯å¦‚ä½•è¢« Tokenizer å¤„ç†å¹¶è½¬æ¢æˆ Tensor çš„ã€‚
    *   **æ€è€ƒ**: å¦‚æœæˆ‘æœ‰è‡ªå·±çš„æ•°æ®æ ¼å¼ï¼Œåº”è¯¥å¦‚ä½•ä¿®æ”¹è¿™é‡Œï¼Ÿ

6.  **å¥–åŠ±å‡½æ•° (Reward Function)**
    *   **é˜…è¯»æ–‡ä»¶**: `verl/utils/reward_score/gsm8k.py` (ä»¥æ•°å­¦ä»»åŠ¡ä¸ºä¾‹)
    *   **é‡ç‚¹**: `compute_score` å‡½æ•°ã€‚
    *   **ç›®å½•æµè§ˆ**: `verl/utils/reward_score/` ä¸‹çš„å…¶ä»–æ–‡ä»¶ï¼Œçœ‹çœ‹å¦‚ä½•ç¼–å†™è‡ªå®šä¹‰è§„åˆ™çš„ Rewardã€‚

7.  **ç®—æ³•é…ç½®**
    *   **é˜…è¯»æ–‡ä»¶**: `verl/trainer/ppo/core_algos.py`
    *   **é‡ç‚¹**: PPO çš„æ ¸å¿ƒæ•°å­¦å®ç°ï¼Œå¦‚ `compute_gae_advantage_return`, `clip_loss` ç­‰ã€‚å¦‚æœä½ æƒ³ä¿®æ”¹ç®—æ³•ç»†èŠ‚ï¼ˆå¦‚å¼•å…¥æ–°çš„ Lossï¼‰ï¼Œè¿™é‡Œæ˜¯å¿…çœ‹ä¹‹åœ°ã€‚

---

## ğŸ—ï¸ ç¬¬å››é˜¶æ®µï¼šè¿›é˜¶æ¶æ„ä¸åº•å±‚ (Advanced Architecture)
**ç›®æ ‡**ï¼šç†è§£ HybridFlow çš„ç²¾é«“ï¼Œä»¥åŠåˆ†å¸ƒå¼æ˜¯å¦‚ä½•å®ç°çš„ã€‚

8.  **Worker å®ç°**
    *   **é˜…è¯»ç›®å½•**: `verl/workers/`
    *   **é‡ç‚¹æ–‡ä»¶**:
        *   `verl/workers/rollout/vllm_rollout.py`: ç»“åˆ vLLM è¿›è¡Œé«˜æ•ˆæ¨ç†ç”Ÿæˆã€‚
        *   `verl/workers/fsdp_workers.py` æˆ– `megatron_workers.py`: å¦‚ä½•ç”¨ FSDP/Megatron è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚
    *   **æ”¶è·**: ç†è§£ `verl` å¦‚ä½•å°† Inference (vLLM) å’Œ Training (PyTorch FSDP) ç»“åˆåœ¨ä¸€èµ·ã€‚

9.  **Controller ä¸ Ray**
    *   **é˜…è¯»ç›®å½•**: `verl/single_controller/`
    *   **é‡ç‚¹**: è¿™é‡Œå°è£…äº†å¯¹ Ray çš„è°ƒç”¨ï¼Œå®ç°äº†æ‰€è°“çš„ "Single Controller" æ¨¡å¼ï¼Œå³ä¸€ä¸ªä¸»æ§èŠ‚ç‚¹è°ƒåº¦å¤šä¸ª Ray Workerã€‚

---

## ğŸ—ºï¸ æ€»ç»“å»ºè®®

å»ºè®®æ‚¨çš„é˜…è¯»é¡ºåºï¼š
1.  **Usage Level**: `examples/ppo_trainer/run_*.sh` -> `examples/ppo_trainer/config/*.yaml`
2.  **Logic Level**: `verl/trainer/main_ppo.py` -> `verl/trainer/ppo/ray_trainer.py`
3.  **Component Level**: `verl/utils/reward_score/*.py` -> `verl/utils/dataset/*.py`
4.  **System Level**: `verl/workers/*.py`
